{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical and mixed type data drift detection on Titanic Dataset\n",
    "### Method\n",
    "The drift detector applies feature-wise two-sample Kolmogorov-Smirnov (K-S) tests for the continuous numerical features and Chi-Squared tests for the categorical features. For multivariate data, the obtained p-values for each feature are aggregated either via the Bonferroni or the False Discovery Rate (FDR) correction. The Bonferroni correction is more conservative and controls for the probability of at least one false positive. The FDR correction on the other hand allows for an expected fraction of false positives to occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alibi in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (3.5.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (4.19.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (1.22.3)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (1.4.2)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (2.27.1)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (9.1.0)\n",
      "Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (0.19.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (1.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (4.2.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.22.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (1.0.2)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (0.3.5.1)\n",
      "Requirement already satisfied: attrs<22.0.0,>=19.2.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from alibi) (21.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (3.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from pandas<2.0.0,>=0.23.3->alibi) (2022.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (1.26.9)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2022.5.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=0.22.0->alibi) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=0.22.0->alibi) (1.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.16)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.6.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.7.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (58.1.0)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.3)\n",
      "Requirement already satisfied: colorama in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from tqdm<5.0.0,>=4.28.1->alibi) (0.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (3.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.7.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (2022.4.24)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from pathy>=0.3.5->spacy[lookups]<4.0.0,>=2.0.0->alibi) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi) (1.16.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Projects\\bluealtair\\testing\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\bluealtair\\testing\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import alibi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "from alibi_detect.utils.saving import save_detector, load_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is FA41-07A3\n",
      "\n",
      " Directory of c:\\Projects\\bluealtair\\testing\\data\\raw\n",
      "\n",
      "05/10/2022  11:17 AM            61,194 train.csv\n",
      "               1 File(s)         61,194 bytes\n",
      "               0 Dir(s)  393,752,371,200 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls ..\\..\\data\\raw\\train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"..\\..\\data\\raw\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis = 0,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.drop([\"Survived\"],axis = 1),data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((183, 11), (183,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop([\"Name\",\"Ticket\",\"PassengerId\"],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data drift detection we need to exclusively provide a list of catgeorical variable columns to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case I have manually created the list of catgorical columns\n",
    "category_list = [\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Cabin\",\"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_per_feature = {}\n",
    "for index,value in enumerate(X.columns):\n",
    "    if value in category_list:\n",
    "        categories_per_feature[index]=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provided to drift detector must be in numpy array. So we need first lable encode catgeorical variable and then convert the dataframe to 2d numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(LabelEncoder().fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data in a reference set and 2 test sets on which we test the data drift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 8), (50, 8), (50, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ref = 50\n",
    "n_test = 50\n",
    "\n",
    "X_ref, X_t0, X_t1 = X[:n_ref], X[n_ref:n_ref + n_test], X[n_ref + n_test:n_ref + 2 * n_test]\n",
    "X_ref.shape, X_t0.shape, X_t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect drift\n",
    "\n",
    "We need to provide the drift detector with the columns which contain categorical features so it knows which features require the Chi-Squared and which ones require the K-S univariate test. We can either provide a dict with as keys the column indices and as values the number of possible categories or just set the values to *None* and let the detector infer the number of categories from the reference data as in the example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save/load an initialised detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory detector_path does not exist and is now created.\n",
      "Directory detector_path\\model does not exist.\n"
     ]
    }
   ],
   "source": [
    "filepath = 'detector_path'  # change to directory where detector is saved\n",
    "save_detector(cd, filepath)\n",
    "cd = load_detector(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check whether the 2 test sets are drifting from the reference data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t0)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'is_drift': 0, 'distance': array([ 0.8660095 ,  0.64231235,  0.16      ,  1.5334947 ,  6.7868133 ,\n",
      "        0.24      , 78.333336  ,  2.127603  ], dtype=float32), 'p_val': array([0.6485574 , 0.42287472, 0.4944631 , 0.6745616 , 0.07901227,\n",
      "       0.09435459, 0.43624088, 0.34514126], dtype=float32), 'threshold': 0.00625}, 'meta': {'name': 'TabularDrift', 'detector_type': 'offline', 'data_type': None, 'version': '0.9.1'}}\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 3, 4, 6, 7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_per_feature.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass -- Chi2 0.866 -- p-value 0.649\n",
      "Sex -- Chi2 0.642 -- p-value 0.423\n",
      "Age -- K-S 0.160 -- p-value 0.494\n",
      "SibSp -- Chi2 1.533 -- p-value 0.675\n",
      "Parch -- Chi2 6.787 -- p-value 0.079\n",
      "Fare -- K-S 0.240 -- p-value 0.094\n",
      "Cabin -- Chi2 78.333 -- p-value 0.436\n",
      "Embarked -- Chi2 2.128 -- p-value 0.345\n"
     ]
    }
   ],
   "source": [
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the feature-level p-values are below the threshold: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['data']['threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in individual feature-wise drift, this is also possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpreds = cd.predict(X_t0, drift_type='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass -- Drift? No! -- Chi2 0.866 -- p-value 0.649\n",
      "Sex -- Drift? No! -- Chi2 0.642 -- p-value 0.423\n",
      "Age -- Drift? No! -- K-S 0.160 -- p-value 0.494\n",
      "SibSp -- Drift? No! -- Chi2 1.533 -- p-value 0.675\n",
      "Parch -- Drift? No! -- Chi2 6.787 -- p-value 0.079\n",
      "Fare -- Drift? No! -- K-S 0.240 -- p-value 0.094\n",
      "Cabin -- Drift? No! -- Chi2 78.333 -- p-value 0.436\n",
      "Embarked -- Drift? No! -- Chi2 2.128 -- p-value 0.345\n"
     ]
    }
   ],
   "source": [
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the second test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t1)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass -- Drift? No! -- Chi2 3.085 -- p-value 0.214\n",
      "Sex -- Drift? No! -- Chi2 0.000 -- p-value 1.000\n",
      "Age -- Drift? No! -- K-S 0.100 -- p-value 0.943\n",
      "SibSp -- Drift? No! -- Chi2 2.125 -- p-value 0.547\n",
      "Parch -- Drift? No! -- Chi2 2.272 -- p-value 0.321\n",
      "Fare -- Drift? No! -- K-S 0.140 -- p-value 0.660\n",
      "Cabin -- Drift? No! -- Chi2 88.000 -- p-value 0.333\n",
      "Embarked -- Drift? No! -- Chi2 2.905 -- p-value 0.234\n"
     ]
    }
   ],
   "source": [
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Drift to file\n",
    "\n",
    "Since there is no logging inbuilt in alibi-detect we need to log data ourselves.We are using logguru for logging due to ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\n",
      "  Using cached loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\projects\\bluealtair\\testing\\env\\lib\\site-packages (from loguru) (0.4.4)\n",
      "Collecting win32-setctime>=1.0.0\n",
      "  Using cached win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Installing collected packages: win32-setctime, loguru\n",
      "Successfully installed loguru-0.6.0 win32-setctime-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Projects\\bluealtair\\testing\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add(\"drift_log.log\", rotation=\"50 MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 08:30:50.432 | INFO     | __main__:<cell line: 1>:1 - {'data': {'is_drift': 0, 'distance': array([ 3.0852714,  0.       ,  0.1      ,  2.125    ,  2.2716577,\n",
      "        0.14     , 88.       ,  2.9049695], dtype=float32), 'p_val': array([0.2138168 , 1.        , 0.9426822 , 0.54687166, 0.32115582,\n",
      "       0.66033244, 0.3328474 , 0.23398817], dtype=float32), 'threshold': 0.00625}, 'meta': {'name': 'TabularDrift', 'detector_type': 'offline', 'data_type': None, 'version': '0.9.1'}}\n"
     ]
    }
   ],
   "source": [
    "logger.info(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e45130a61b757eb2e10094738f7703e073112f48eda961073e68e07ec6be6856"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
